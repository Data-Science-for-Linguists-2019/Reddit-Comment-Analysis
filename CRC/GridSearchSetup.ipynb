{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If you're examining this, this is being written to be copied and pasted into a python script. Thus, little to no markdown will be here. Is the data small enough that I could run this here and now? Probably. Still going to SQUEUE it anyway for practice and stuff, as well as being able to test many combinations. (Also, access to job statistics)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Best Parameters\n",
      "-------------------------------------\n",
      "Support Vector Parameters\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "above50t = pd.read_pickle(\"MLdata.pkl\")\n",
    "\n",
    "print(\"Multinomial Best Parameters\")\n",
    "print(\"-------------------------------------\")\n",
    "model = Pipeline(steps=[('Tfidf', TfidfVectorizer(min_df=2)), ('MNB', MultinomialNB())])\n",
    "param_grid = {\n",
    "    \"Tfidf__max_features\":[None, 1500, 3000, 5000, 7500],\n",
    "    \"Tfidf__min_df\":[1,2,3,4,5],\n",
    "    \"Tfidf__max_df\":[1,2,3,4,5],\n",
    "    \"Tfidf__ngram_range\":[(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)],\n",
    "    \"MNB__alpha\":[0.01, 0.25, 0.5, 0.75, 1.00]\n",
    "}\n",
    "grid = GridSearchCV(model, param_grid, n_jobs=4, cv=5)\n",
    "grid.fit(above50t[\"body\"], above50t[\"subreddit\"])\n",
    "print(\"Best Parameters :\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Support Vector Parameters\")\n",
    "print(\"-------------------------------------\")\n",
    "model = Pipeline(steps=[('Tfidf', TfidfVectorizer(min_df=2)), ('SVC', SVC(C=1E5))])\n",
    "param_grid = {\n",
    "    \"Tfidf__max_features\":[None, 1500, 3000, 5000, 7500],\n",
    "    \"Tfidf__min_df\":[1,2,3,4,5],\n",
    "    \"Tfidf__max_df\":[1,2,3,4,5],\n",
    "    \"Tfidf__ngram_range\":[(1,1),(1,2),(1,3),(2,2),(2,3),(3,3)],\n",
    "    \"SVC__kernel\":[\"linear\", \"poly\", \"rbf\", \"signmoid\"]\n",
    "}\n",
    "grid = GridSearchCV(model, param_grid, n_jobs=4, cv=5)\n",
    "grid.fit(above50t[\"body\"], above50t[\"subreddit\"])\n",
    "print(\"Best Parameters :\")\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    8054\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(above50t.subreddit == None).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
